import pandas as pd
import numpy as np
from sklearn.model_selection import cross_val_score, cross_val_predict, train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import (roc_curve, auc, accuracy_score, precision_score, 
                             recall_score, f1_score, roc_auc_score, confusion_matrix)
import matplotlib.pyplot as plt
from sklearn.model_selection import StratifiedKFold

# Load the training dataset
train_file = "training_set.csv"
train_data = pd.read_csv(train_file)

# Define input features (X) and target (y)
X = train_data[['grade', 'age', 'gender', 'vision', 'ser']]
y = train_data['occur']

# Initialize Random Forest Classifier
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)

# 10x Cross-validation with ROC Curve generation
cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)
y_pred_proba = cross_val_predict(rf_model, X, y, cv=cv, method='predict_proba')[:, 1]
y_pred = cross_val_predict(rf_model, X, y, cv=cv, method='predict')

# Metrics for 10-fold Cross-Validation
accuracy = accuracy_score(y, y_pred)
precision = precision_score(y, y_pred)
recall = recall_score(y, y_pred)
f1 = f1_score(y, y_pred)
auc_value = roc_auc_score(y, y_pred_proba)

# Generate ROC Curve
fpr, tpr, _ = roc_curve(y, y_pred_proba)

# Plot ROC Curve for Cross-Validation
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (AUC = {auc_value:.2f})')
plt.plot([0, 1], [0, 1], color='gray', linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve - 10-Fold Cross Validation')
plt.legend(loc='lower right')
plt.show()

# Print Cross-Validation Metrics
print("\n--- 10x Cross-Validation Metrics ---")
print(f"Accuracy: {accuracy:.3f}")
print(f"Precision: {precision:.3f}")
print(f"Recall: {recall:.3f}")
print(f"F1-Score: {f1:.3f}")
print(f"AUC: {auc_value:.3f}")

# ----------------------------------------------------------
# External Validation
# Load the external test dataset
external_file = "external_test.csv"  # Ensure the file is provided
external_data = pd.read_csv(external_file)

# Extract input features (X_test) and target (y_test)
X_test = external_data[['grade', 'age', 'gender', 'vision', 'ser']]
y_test = external_data['occur']

# Train the Random Forest model on the entire training dataset
rf_model.fit(X, y)

# Make predictions on the external validation set
y_test_pred_proba = rf_model.predict_proba(X_test)[:, 1]
y_test_pred = rf_model.predict(X_test)

# Metrics for External Validation
accuracy_ext = accuracy_score(y_test, y_test_pred)
precision_ext = precision_score(y_test, y_test_pred)
recall_ext = recall_score(y_test, y_test_pred)
f1_ext = f1_score(y_test, y_test_pred)
auc_value_ext = roc_auc_score(y_test, y_test_pred_proba)

# Generate ROC Curve for External Validation
fpr_ext, tpr_ext, _ = roc_curve(y_test, y_test_pred_proba)

# Plot ROC Curve for External Validation
plt.figure(figsize=(8, 6))
plt.plot(fpr_ext, tpr_ext, color='green', lw=2, label=f'ROC curve (AUC = {auc_value_ext:.2f})')
plt.plot([0, 1], [0, 1], color='gray', linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve - External Validation')
plt.legend(loc='lower right')
plt.show()

# Print External Validation Metrics
print("\n--- External Validation Metrics ---")
print(f"Accuracy: {accuracy_ext:.3f}")
print(f"Precision: {precision_ext:.3f}")
print(f"Recall: {recall_ext:.3f}")
print(f"F1-Score: {f1_ext:.3f}")
print(f"AUC: {auc_value_ext:.3f}")
